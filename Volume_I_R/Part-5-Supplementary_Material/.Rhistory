if (!require("MCMC")){
install.packages("MCMC")
}
library(MCMC)
install.packages("mcmc")
if (!require("MCMC")){
install.packages("MCMC")
}
library(MCMC)
if (!require("MCMCpack")){
install.packages("MCMCpack")
}
library(MCMCpack)
if (!require("MASS")){
install.packages("MASS")
}
library(MASS)
attach(Boston) # normally we don't attach the data
cat("The mean is: ", mean(crim))
cat("\nThe median is: ", median(crim))
cat("\nThe range is: ", range(crim))
mode(crim)
?mode()
medv
sort(medv)
names(sort(-table(medv)))
?table()
1 * 1/6 + 2 * 1/6 + 3 * 1/6 + 4 * 1/6 + 5 * 1/6 + 6 * 1/6
corr(medv, rm)
cor(medv, rm)
cov(medv, rm)
?sample()
x <- sample(medv, 5, replace=TRUE)
x
x <- sample(medv, 5, replace=TRUE)
mean(x)
x <- sample(medv, 5, replace=TRUE)
mean(x)
x <- sample(medv, 5, replace=TRUE)
mean(x)
x <- sample(medv, 5, replace=TRUE)
mean(x)
x <- sample(medv, 5, replace=TRUE)
mean(x)
x <- sample(medv, 5, replace=TRUE)
mean(x)
x <- sample(medv, 5, replace=TRUE)
mean(x)
mean(medv)
sample_means <- []
#sample_means <- []
for (i in 1:50) {
sample_means[i] <- mean(sample(medv, 5, replace=TRUE))
}
rep(0, 50)
sample_means <- rep(0, 50)
for (i in 1:50) {
sample_means[i] <- mean(sample(medv, 5, replace=TRUE))
}
hist(sample_means)
plot(sample_means)
se(sample_means)
std.error(sample_means)
sd(sample_means)/sqrt(length((sample_means)))
var(medv)
var(medv)
sd(medv)
var(medv)
sd(medv)
sd(medv)^2
var(medv)
sd(medv)
sd(medv)^2
n <- length(sample_means)
xbar <- mean(medv)
margin_of_error <- qt(0.975, df=n-1) * sd(sample_means)/sqrt(n)
margin_of_error
lower <- xbar - margin_of_error
higher <- xbar + margin_of_error
print("CI is", lower, "to", higher)
lower <- xbar - margin_of_error
higher <- xbar + margin_of_error
print("CI is" + lower + "to" + higher)
lower <- xbar - margin_of_error
higher <- xbar + margin_of_error
cat("CI is" + lower + "to" + higher)
lower <- xbar - margin_of_error
higher <- xbar + margin_of_error
cat("CI is" + str(lower) + "to" + str(higher))
lower
higher
lower <- xbar - margin_of_error
higher <- xbar + margin_of_error
cat("CI is", str(lower), "to", str(higher))
str(lower)
str(lower)
lower <- xbar - margin_of_error
higher <- xbar + margin_of_error
cat("CI is", lower, "to", str(higher))
lower <- xbar - margin_of_error
higher <- xbar + margin_of_error
cat("CI is", lower, "to", higher)
z_scores <- (sample_means - mean(sample_means)) / sd(sample_means)
z_scores
hist(z_scores)
plot(sort(z_scores))
plot(sort(z_scores))
plot(sort(z_scores))
plot(z_scores)
plot(sort(z_scores))
plot(sort(z_scores))
abline(a=0, b=1)
plot(sort(z_scores))
abline(a=-2, b=2)
plot(sort(z_scores))
abline(a=-2, b=50)
#plot(sort(z_scores))
qqnorm(z_scores)
abline(a=0, b=1)
?qt()
dt(sample_means, 1)
plot(dt(sample_means, 1))
plot(sort(dt(sample_means, 1)))
ypos <- dt(sample_means, 1)
plot (ypos , type = "l")
ypos <- dt(sample_means, n-1)
plot (ypos , type = "l")
ypos <- dt(sample_means, n-1)
hist(ypos , type = "l")
ypos <- dt(sample_means, n-1)
hist(ypos)
ypos <- pt(sample_means, n-1)
hist(ypos)
ypos <- rt(sample_means, n-1)
hist(ypos)
?rt()
result <- t.test(sample_means, mu = mean(sample_means))
print(result$statistic)
results
result$estimate
result
result <- t.test(sample_means, mu = mean(sample_means))
result
?t.test()
ypos <- rt(50, n-1)
hist(ypos)
ypos <- rt(1000, n-1)
hist(ypos)
head(iris)
set.seed(1234)
irisCluster <- kmeans(iris[, 3:4], 3, nstart=20)
irisCluster
table(irisCluster$cluster, iris$Species)
plot(iris$Petal.Length, iris$Petal.Width, pch=21, bg=c("red","green3","blue")
[unclass(irisCluster$cluster)], main="Iris Data")
if (!require(flexclust)){
install.packages("flexclust")
}
library("NbClust")
install.packages("NbClust")
if (!require(flexclust)){
install.packages("flexclust")
}
library("flexclust")
if (!require(NbClust)){
install.packages("NbClust")
}
library("NbClust")
data(wine, package="rattle")
if (!require(flexclust)){
install.packages("flexclust")
}
library("flexclust")
if (!require(NbClust)){
install.packages("NbClust")
}
library("NbClust")
if (!require(rattle)){
install.packages("rattle")
}
library("rattle")
data(wine, package="rattle")
names(wine)
head(wine)
df <- scale(wine[-1])
head(df)
wsplot <- function(data, nc=15, seed=1234){
wss <- (nrow(data)-1)*sum(apply(data,2,var))
for (i in 2:nc){
set.seed(seed)
wss[i] <- sum(kmeans(data,centers=i)$withinss)
}
plot(1:nc, wss, type="b", xlab="Number of Clusters",
ylab="Within groups sum of squares")
}
wsplot(df)
# uses library(NbClust)
set.seed(1234)
nc <- NbClust(df, min.nc=2, max.nc=15, method="kmeans")
table(nc$Best.n[1,])
barplot(table(nc$Best.n[1,]),
xlab="Number of Clusters", ylab="Number of Criteria",
main="Number of Clusters Chosen by 26 Criteria")
set.seed(1234)
fit.km <- kmeans(df, 3, nstart=25)
fit.km$size
fit.km$centers
aggregate(wine[-1], by=list(cluster=fit.km$cluster), mean)
ct.km <- table(wine$Type, fit.km$cluster)
ct.km
# uses library(flexclust)
randIndex(ct.km)
if (!require(NbClust)){
install.packages("NbClust")
}
library("NbClust")
set.seed(1234)
x <- rep(0, 60)
y <- rep(0, 60)
x[1:20] <- rnorm(20, mean=10, sd=3)
y[1:20] <- rnorm(20, mean=3, sd=1)
x[21:40] <- rnorm(20, mean=27, sd=4)
y[21:40] <- rnorm(20, mean=2, sd=1)
x[41:60] <- rnorm(20, mean=41, sd=3)
y[41:60] <- rnorm(20, mean=5, sd=1)
# uncomment the next two lines to see what happens
# with a more uniform distribution
#x <- rnorm(60, mean=30, sd=10)
#y <- rnorm(60, mean=3, sd=2)
true <- c(rep(1,20), rep(2,20), rep(3,20))
plot(x, y, cex=1.5, pch=c(15, 16, 17)[true])
set.seed(1234)
df <- data.frame(cbind(x, y))
res <- kmeans(df, 3, iter.max=1, nstart=1 )
plot(x, y, col=c("orange", "green", "purple")[res$cluster], cex=1.5, pch=c(15, 16, 17)[true])
set.seed(1234)
res3 <- kmeans(df, 3,  nstart=1 )
plot(x, y, col=c("orange", "green", "purple")[res3$cluster], cex=1.5, pch=c(15, 16, 17)[true])
set.seed(1234)
res2 <- kmeans(df, 2,  nstart= 5)
plot(x, y, col=c("orange", "green", "purple", "blue")[res2$cluster], cex=1.5, pch=c(15, 16, 17)[true])
set.seed(1234)
res4 <- kmeans(df, 4,  nstart= 5)
plot(x, y, col=c("orange", "green", "purple", "blue")[res4$cluster], cex=1.5, pch=c(15, 16, 17)[true])
set.seed(1234)
res5 <- kmeans(df, 5,  nstart= 5)
plot(x, y, col=c("orange", "green", "purple", "blue", "black")[res5$cluster], cex=1.5, pch=c(15, 16, 17)[true])
print(paste("k=2: ", sum(res2$withinss)))
print(paste("k=3: ", sum(res3$withinss)))
print(paste("k=4: ", sum(res4$withinss)))
print(paste("k=5: ", sum(res5$withinss)))
plot_withinss <- function(df, max_clusters){
withinss <- rep(0, max_clusters-1)
for (i in 2:max_clusters){
set.seed(1234)
withinss[i] <- sum(kmeans(df, i)$withinss)
}
plot(2:max_clusters, withinss[2:max_clusters], type="o", xlab="K", ylab="Within Sum Squares")
}
plot_withinss(df, 9)
# uses library(NbClust)
set.seed(1234)
nc <- NbClust(df, min.nc=2, max.nc=9, method="kmeans")
t <- table(nc$Best.n[1,])
t
barplot(t, xlab="Number of Clusters", ylab = "Criteria")
par(mfrow=c(2,1))
plot(x, y, col=c("orange", "green", "purple", "blue")[res3$cluster], cex=1.5, pch=c(15, 16, 17)[true])
plot(x, y, col=c("orange", "green", "purple", "blue")[res4$cluster], cex=1.5, pch=c(15, 16, 17)[true])
if (!require(flexclust)){
install.packages("flexclust")
}
library("flexclust")
if (!require(NbClust)){
install.packages("NbClust")
}
library("NbClust")
# uses library(flexclust)
data(nutrient)
str(nutrient)
head(nutrient)
nutrient.scaled <- scale(nutrient)
head(nutrient.scaled)
d <- dist(nutrient.scaled)
fit.average <- hclust(d, method="average")
plot(fit.average, hang=-1, cex=.8,
main="Hierarchical Clustering")
library(NbClust)
nutrient$Type <- "BEEF"
nutrient$Type[6:7] <- "CHICKEN"
nutrient$Type[9:10] <- "LAMB"
nutrient$Type[16:27] <- "SEAFOOD"
nutrient$Type[11:13] <- "PORK"
nutrient$Type <- factor(nutrient$Type)
for (c in 3:11){
cluster_cut <- cutree(fit.average, c)
table_cut <- table(cluster_cut, nutrient$Type)
print(table_cut)
ri <- randIndex(table_cut)
print(paste("cut=", c, "Rand index = ", ri))
}
for (c in 3:16){
cluster_cut <- cutree(fit.average, c)
table_cut <- table(cluster_cut, nutrient$calcium)
print(table_cut)
ri <- randIndex(table_cut)
print(paste("cut=", c, "Rand index = ", ri))
}
if (!require(caret)){
install.packages("caret")
}
library("caret")
if (!require(tree)){
install.packages("tree")
}
library("tree")
if (!require(MASS)){
install.packages("MASS")
}
library("MASS")
names(Boston)
# divide into train and test
set.seed(1234)
i <- sample(nrow(Boston), 0.8*nrow(Boston), replace = FALSE)
train <- Boston[i,]
test <- Boston[-i,]
lm1 <- lm(medv~., data=train)
summary(lm1)
pred <- predict(lm1, newdata=test)
cor_lm <- cor(pred, test$medv)
rmse_lm <- sqrt(mean((pred-test$medv)^2))
tree1 <- tree(medv~., data=train)
summary(tree1)
pred <- predict(tree1, newdata=test)
print(paste('correlation:', cor(pred, test$medv)))
rmse_tree <- sqrt(mean((pred-test$medv)^2))
print(paste('rmse:', rmse_tree))
plot(tree1)
text(tree1, cex=0.5, pretty=0)
cv_tree <- cv.tree(tree1)
plot(cv_tree$size, cv_tree$dev, type='b')
tree_pruned <- prune.tree(tree1, best=5)
plot(tree_pruned)
text(tree_pruned, pretty=0)
pred_pruned <- predict(tree_pruned, newdata=test)
cor_pruned <- cor(pred_pruned, test$medv)
rmse_pruned <- rmse_pruned <- sqrt(mean((pred_pruned-test$medv)^2))
if (!require(tree)){
install.packages("tree")
}
library("tree")
if (!require(MASS)){
install.packages("MASS")
}
library("MASS")
if (!require(randomForest)){
install.packages("randomForest")
}
library("randomForest")
# uses library(randomForest)
set.seed(1234)
rf <- randomForest(medv~., data=train, importance=TRUE)
rf
pred_rf <- predict(rf, newdata=test)
cor_rf <- cor(pred_rf, test$medv)
print(paste('corr:', cor_rf))
rmse_rf <- sqrt(mean((pred_rf-test$medv)^2))
print(paste('rmse:', rmse_rf))
bag <- randomForest(medv~., data=train, mtry=13)
bag
pred_bag <- predict(bag, newdata=test)
cor_bag <- cor(pred_bag, test$medv)
rmse_bag <- sqrt(mean((pred_bag-test$medv)^2))
if (!require(rpart)){
install.packages("rpart")
}
library("rpart")
if (!require(tree)){
install.packages("tree")
}
library("tree")
# uses library(rpart)
tree_iris <- rpart(Species~., data=iris, method="class")
tree_iris
summary(tree_iris)
plot(tree_iris, uniform=TRUE)
text(tree_iris, use.n=TRUE, all=TRUE, cex=.6)
# uses library(tree)
tree_iris2 <- tree(Species~., data=iris)
tree_iris2
summary(tree_iris2)
plot(tree_iris2)
text(tree_iris2, cex=0.5, pretty=0)
set.seed(1958)
i <- sample(150, 100, replace=FALSE)
train <- iris[i,]
test <- iris[-i,]
tree_iris3 <- tree(Species~., data=train)
pred <- predict(tree_iris3, newdata=test, type="class")
table(pred, test$Species)
mean(pred==test$Species)
if (!require(caret)){
install.packages("caret")
}
library("caret")
# uses library(caret)
data(iris)
i <- sample(1:150, 100, replace=FALSE)
train <- iris[i,]
test <- iris[-i,]
set.seed(1234)
pca_out <- preProcess(train[,1:4], method=c("center", "scale", "pca"))
pca_out
train_pc <- predict(pca_out, train[, 1:4])
test_pc <- predict(pca_out, test[,])
plot(test_pc$PC1, test_pc$PC2, pch=c(23,21,22)[unclass(test_pc$Species)], bg=c("red","green","blue")[unclass(test$Species)])
train_df <- data.frame(train_pc$PC1, train_pc$PC2, train$Species)
test_df <- data.frame(test_pc$PC1, test_pc$PC2, test$Species)
library(class)
set.seed(1234)
pred <- knn(train=train_df[,1:2], test=test_df[,1:2], cl=train_df[,3], k=3)
mean(pred==test$Species)
# uses library(tree)
colnames(train_df) <- c("PC1", "PC2", "Species")
colnames(test_df) <- c("PC1", "PC2", "Species")
set.seed(1234)
tree1 <- tree(Species~., data=train_df)
plot(tree1)
text(tree1, cex=0.5, pretty=0)
pred <- predict(tree1, newdata=test_df, type="class")
mean(pred==test$Species)
?lda()
# uses library(MASS) for lda()
lda1 <- lda(Species~., data=train)
lda1$means
lda_pred <- predict(lda1, newdata=test, type="class")
lda_pred$class
mean(lda_pred$class==test$Species)
plot(lda_pred$x[,1], lda_pred$x[,2], pch=c(23,21,22)[unclass(lda_pred$class)], bg=c("red","green","blue")[unclass(test_pc$Species)])
