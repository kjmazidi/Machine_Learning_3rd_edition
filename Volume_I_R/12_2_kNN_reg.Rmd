---
editor_options:
  chunk_output_type: inline
output:
  pdf_document: default
  html_document:
    df_print: paged
---
# kNN Clustering - Regression
### Karen Mazidi

This example uses the Auto data set in package ISLR. First we try linear regression as a baseline and then see if knn can beat the linear model. 

```{r}
library(ISLR)
attach(Auto)
Auto$origin <- as.factor(origin)
```

Build a linear model with all predictors. 

```{r}
lm1 <- lm(mpg ~.-name, data=Auto)
summary(lm1)
```

## Train and test on a linear model

The results from lm1 indicated that weight, year, and origin appear to be significant predictors so let's build a model just from those. 

First, randomly sample 80% from the data set, and let those indices be for training while the others are for the test set. 

```{r}
set.seed(1958)  # for reproducible results
i <- sample(1:nrow(Auto), round(nrow(Auto)*0.8), replace=FALSE)
train <- Auto[i,]
test <- Auto[-i,]
lm2 <- lm(mpg~weight+year+origin, data=train)
pred <- predict(lm2, newdata=test)
cor_lm <- cor(pred, test$mpg)
mse_lm <- mean((pred - test$mpg)^2)
print(paste("cor=", cor_lm))
print(paste("mse=", mse_lm))
```


The correlation for the linear model was 92% which is good. Can kNN do better?

### kNN for regression

We will use the same train and test set as we used for the linear model. We will train on weight, year and origin as for the linear model.

```{r}
library(caret)
train$origin <- as.integer(train$origin)
test$origin <- as.integer(test$origin)
fit <- knnreg(train[,2:8],train[,1],k=3)
predictions <- predict(fit, test[,2:8])
cor_knn1 <- cor(predictions, test$mpg)
mse_knn1 <- mean((predictions - test$mpg)^2)
print(paste("cor=", cor_knn1))
print(paste("mse=", mse_knn1))
```

So the results were not as good for knn, the correlation lower and the mse was higher.

As discussed in class, we know that clustering algorithms work best if the data is scaled, so let's scale the data and try again.

```{r}
train_scaled <- train[, 2:8]  # omit name and don't scale mpg
means <- sapply(train_scaled, mean)
stdvs <- sapply(train_scaled, sd)
train_scaled <- scale(train_scaled, center=means, scale=stdvs)
test_scaled <- scale(test[, 2:8], center=means, scale=stdvs)
                      
fit <- knnreg(train_scaled, train$mpg, k=3)
predictions <- predict(fit, test_scaled)
cor_knn2 <- cor(predictions, test$mpg)
mse_knn2 <- mean((predictions - test$mpg)^2)
print(paste("cor=", cor_knn2))
print(paste("mse=", mse_knn2))
```

Wow, scaling improved the results. Correlation is higher and mse is lower than the liner model. 

### Finding the best k

Try various values of k and plot the results. 

```{r}
cor_k <- rep(0, 20)
mse_k <- rep(0, 20)
i <- 1
for (k in seq(1, 39, 2)){
  fit_k <- knnreg(train_scaled,train$mpg, k=k)
  pred_k <- predict(fit_k, test_scaled)
  cor_k[i] <- cor(pred_k, test$mpg)
  mse_k[i] <- mean((pred_k - test$mpg)^2)
  print(paste("k=", k, cor_k[i], mse_k[i]))
  i <- i + 1
}

plot(1:20, cor_k, lwd=2, col='red', ylab="", yaxt='n')
par(new=TRUE)
plot(1:20, mse_k, lwd=2, col='blue', labels=FALSE, ylab="", yaxt='n')
```
Find the best k

```{r}
which.min(mse_k)
```

```{r}
which.max(cor_k)
```


### k=15

Lets pick a different k and compare results. We run the model above. It is slightly worse than k=3. So the plot is very informative when picking k.

```{r}
fit_15 <- knnreg(train_scaled,train$mpg,k=15)
predictions_15 <- predict(fit_15, test_scaled)
cor_knn15 <- cor(predictions_15, test$mpg)
mse_knn15 <- mean((predictions_15 - test$mpg)^2)
print(paste("cor=", cor_knn15))
print(paste("mse=", mse_knn15))
```



