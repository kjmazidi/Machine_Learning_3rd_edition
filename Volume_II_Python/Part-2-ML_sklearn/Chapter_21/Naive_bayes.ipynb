{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "## Titanic data\n",
    "\n",
    "This notebook runs the Naive Bayes algorithm on the Titanic data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  survived     sex      age\n",
      "0       1         1  female  29.0000\n",
      "1       1         1    male   0.9167\n",
      "2       1         0  female   2.0000\n",
      "3       1         0    male  30.0000\n",
      "4       1         0  female  25.0000\n",
      "\n",
      "Dimensions of data frame: (1309, 4)\n"
     ]
    }
   ],
   "source": [
    "### load the data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/titanic3.csv', usecols=['pclass', 'survived', 'sex', 'age'])\n",
    "print(df.head())\n",
    "print('\\nDimensions of data frame:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived  sex      age\n",
       "0       0         1    0  29.0000\n",
       "1       0         1    1   0.9167\n",
       "2       0         0    0   2.0000\n",
       "3       0         0    1  30.0000\n",
       "4       0         0    0  25.0000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert columns to factors\n",
    "df.survived = df.survived.astype('category').cat.codes\n",
    "df.pclass = df.pclass.astype('category').cat.codes\n",
    "df.sex = df.sex.astype('category').cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass        0\n",
       "survived      0\n",
       "sex           0\n",
       "age         263\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "import numpy as np\n",
    "\n",
    "age_mean = np.mean(df.age)\n",
    "df.age.fillna(age_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (1047, 3)\n",
      "test size: (262, 3)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.loc[:, ['pclass', 'age', 'sex']]\n",
    "y = df.survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print('train size:', X_train.shape)\n",
    "print('test size:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7277936962750716"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.6641221374045801\n",
      "precision score:  0.62\n",
      "recall score:  0.31\n",
      "f1 score:  0.4133333333333334\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('accuracy score: ', accuracy_score(y_test, pred))\n",
    "print('precision score: ', precision_score(y_test, pred))\n",
    "print('recall score: ', recall_score(y_test, pred))\n",
    "print('f1 score: ', f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[143,  19],\n",
       "       [ 69,  31]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76       162\n",
      "           1       0.62      0.31      0.41       100\n",
      "\n",
      "    accuracy                           0.66       262\n",
      "   macro avg       0.65      0.60      0.59       262\n",
      "weighted avg       0.65      0.66      0.63       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Bernoulli NB instead of Multinomial\n",
    "\n",
    "Both the Multinomial and Bernoulli models handle discrete data. The difference is that MultinomialNB uses frequency counts per class and BernoulliNB works best with binary features. In the Titanic data, sex is binary, pclass is multinomial, and age is Gaussian. The sklearn library provides models for all 3 types of data. See the documentation:\n",
    "\n",
    "* [BernoulliNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html)\n",
    "* [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "* [Gaussian](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.7786259541984732\n",
      "precision score:  0.7560975609756098\n",
      "recall score:  0.62\n",
      "f1 score:  0.6813186813186813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       162\n",
      "           1       0.76      0.62      0.68       100\n",
      "\n",
      "    accuracy                           0.78       262\n",
      "   macro avg       0.77      0.75      0.76       262\n",
      "weighted avg       0.78      0.78      0.77       262\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf2 = BernoulliNB()\n",
    "clf2.fit(X_train, y_train)\n",
    "pred2 = clf2.predict(X_test)\n",
    "print('accuracy score: ', accuracy_score(y_test, pred2))\n",
    "print('precision score: ', precision_score(y_test, pred2))\n",
    "print('recall score: ', recall_score(y_test, pred2))\n",
    "print('f1 score: ', f1_score(y_test, pred2))\n",
    "print(classification_report(y_test, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bernoulli model significantly outperformed the Multinomial model. The Bernoulli model binarizes predictors. The sex predictor is already binary, pclass has 3 levels but would be binarized by the training algorithm. The age predictor would also be binarized into above/below an age. \n",
    "\n",
    "Determining beforehand which algorithm to use is difficult, which is why two different algorithms were tried here. Besides the handling of data, the two algorithms are different. MultinomialNB considers counts for multiple features whereas BernoulliNB cares about the presence *or* the absence of a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
